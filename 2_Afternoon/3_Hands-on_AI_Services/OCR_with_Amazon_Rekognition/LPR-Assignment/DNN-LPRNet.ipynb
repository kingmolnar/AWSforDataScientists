{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LPRNet: License Plate Recognition via Deep Neural Networks\n",
    "\n",
    "Download the original code from GitHub \n",
    "https://github.com/sirius-ai/LPRNet_Pytorch\n",
    "\n",
    "https://arxiv.org/abs/1806.10447v1\n",
    "\n",
    "Sergey Zherzdev, Alexey Gruzdev\n",
    "\n",
    "This paper proposes LPRNet - end-to-end method for Automatic License Plate Recognition without preliminary character segmentation. Our approach is inspired by recent breakthroughs in Deep Neural Networks, and works in real-time with recognition accuracy up to 95% for Chinese license plates: 3 ms/plate on nVIDIA GeForce GTX 1080 and 1.3 ms/plate on Intel Core i7-6700K CPU. LPRNet consists of the lightweight Convolutional Neural Network, so it can be trained in end-to-end way. To the best of our knowledge, LPRNet is the first real-time License Plate Recognition system that does not use RNNs. As a result, the LPRNet algorithm may be used to create embedded solutions for LPR that feature high level accuracy even on challenging Chinese license plates.\n",
    "\n",
    "Subjects:\tComputer Vision and Pattern Recognition (cs.CV)\n",
    "\n",
    "Cite as:\tarXiv:1806.10447 [cs.CV]\n",
    " \t(or arXiv:1806.10447v1 [cs.CV] for this version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import *\n",
    "from imutils import paths\n",
    "# import numpy as np\n",
    "import random\n",
    "# import cv2\n",
    "# import os\n",
    "import sys\n",
    "#sys.path.insert(0, os.getcwd())\n",
    "##from data.load_data import CHARS, CHARS_DICT, LPRDataLoader\n",
    "##from PIL import Image, ImageDraw, ImageFont\n",
    "###from model.LPRNet import build_lprnet\n",
    "#from LPRNet import build_lprnet\n",
    "# import LPRNet\n",
    "# import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import *\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "##import argparse\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "From `model/LPRNet/LPRNet.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class small_basic_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(small_basic_block, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class LPRNet(nn.Module):\n",
    "    def __init__(self, lpr_max_len, phase, class_num, dropout_rate):\n",
    "        super(LPRNet, self).__init__()\n",
    "        self.phase = phase\n",
    "        self.lpr_max_len = lpr_max_len\n",
    "        self.class_num = class_num\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1), # 0\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),  # 2\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1)),\n",
    "            small_basic_block(ch_in=64, ch_out=128),    # *** 4 ***\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),  # 6\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2)),\n",
    "            small_basic_block(ch_in=64, ch_out=256),   # 8\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),  # 10\n",
    "            small_basic_block(ch_in=256, ch_out=256),   # *** 11 ***\n",
    "            nn.BatchNorm2d(num_features=256),   # 12\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2)),  # 14\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 4), stride=1),  # 16\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),  # 18\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(in_channels=256, out_channels=class_num, kernel_size=(13, 1), stride=1), # 20\n",
    "            nn.BatchNorm2d(num_features=class_num),\n",
    "            nn.ReLU(),  # *** 22 ***\n",
    "        )\n",
    "        self.container = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=448+self.class_num, out_channels=self.class_num, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            # nn.BatchNorm2d(num_features=self.class_num),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(in_channels=self.class_num, out_channels=self.lpr_max_len+1, kernel_size=3, stride=2),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        keep_features = list()\n",
    "        for i, layer in enumerate(self.backbone.children()):\n",
    "            x = layer(x)\n",
    "            if i in [2, 6, 13, 22]: # [2, 4, 8, 11, 22]\n",
    "                keep_features.append(x)\n",
    "\n",
    "        global_context = list()\n",
    "        for i, f in enumerate(keep_features):\n",
    "            if i in [0, 1]:\n",
    "                f = nn.AvgPool2d(kernel_size=5, stride=5)(f)\n",
    "            if i in [2]:\n",
    "                f = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))(f)\n",
    "            f_pow = torch.pow(f, 2)\n",
    "            f_mean = torch.mean(f_pow)\n",
    "            f = torch.div(f, f_mean)\n",
    "            global_context.append(f)\n",
    "\n",
    "        x = torch.cat(global_context, 1)\n",
    "        x = self.container(x)\n",
    "        logits = torch.mean(x, dim=2)\n",
    "\n",
    "        return logits\n",
    "\n",
    "def build_lprnet(lpr_max_len=8, phase=False, class_num=66, dropout_rate=0.5):\n",
    "\n",
    "    Net = LPRNet(lpr_max_len, phase, class_num, dropout_rate)\n",
    "\n",
    "    if phase == \"train\":\n",
    "        return Net.train()\n",
    "    else:\n",
    "        return Net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a modified DataLoader\n",
    "The following code has been adjusted from the `data/load_data.py` file in the original repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pre-trained model uses this encoding.\n",
    "# Even though we only use the Latin alphabet\n",
    "# we need to keep the same encoding as the trained model\n",
    "CHARS = ['京', '沪', '津', '渝', '冀', '晋', '蒙', '辽', '吉', '黑',\n",
    "         '苏', '浙', '皖', '闽', '赣', '鲁', '豫', '鄂', '湘', '粤',\n",
    "         '桂', '琼', '川', '贵', '云', '藏', '陕', '甘', '青', '宁',\n",
    "         '新',\n",
    "         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K',\n",
    "         'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "         'W', 'X', 'Y', 'Z', 'I', 'O', '-'\n",
    "         ]\n",
    "\n",
    "CHARS_DICT = {char:i for i, char in enumerate(CHARS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPRDataLoader(Dataset):\n",
    "    def __init__(self, img_dir, imgSize, lpr_max_len, PreprocFun=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_paths = []\n",
    "        for i in range(len(img_dir)):\n",
    "            self.img_paths += [el for el in paths.list_images(img_dir[i])]\n",
    "        random.shuffle(self.img_paths)\n",
    "        self.img_size = imgSize\n",
    "        self.lpr_max_len = lpr_max_len\n",
    "        if PreprocFun is not None:\n",
    "            self.PreprocFun = PreprocFun\n",
    "        else:\n",
    "            self.PreprocFun = self.transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.img_paths[index]\n",
    "        Image = cv2.imread(filename)\n",
    "        height, width, _ = Image.shape\n",
    "        if height != self.img_size[1] or width != self.img_size[0]:\n",
    "            Image = cv2.resize(Image, self.img_size)\n",
    "        Image = self.PreprocFun(Image)\n",
    "\n",
    "        basename = os.path.basename(filename)\n",
    "        imgname, suffix = os.path.splitext(basename)\n",
    "        imgname = imgname.split(\"-\")[0].split(\"_\")[0]\n",
    "        label = list()\n",
    "        for c in imgname:\n",
    "            # one_hot_base = np.zeros(len(CHARS))\n",
    "            # one_hot_base[CHARS_DICT[c]] = 1\n",
    "            label.append(CHARS_DICT[c])\n",
    "\n",
    "        if len(label) == 8:\n",
    "            if self.check(label) == False:\n",
    "                print(imgname)\n",
    "                assert 0, \"Error label ^~^!!!\"\n",
    "\n",
    "        return Image, label, len(label)\n",
    "\n",
    "    def transform(self, img):\n",
    "        img = img.astype('float32')\n",
    "        img -= 127.5\n",
    "        img *= 0.0078125\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "        return img\n",
    "\n",
    "    def check(self, label):\n",
    "        if label[2] != CHARS_DICT['D'] and label[2] != CHARS_DICT['F'] \\\n",
    "                and label[-1] != CHARS_DICT['D'] and label[-1] != CHARS_DICT['F']:\n",
    "            print(\"Error label, Please check!\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification from the original LPRDataLoader. This version is customized for the Atlanta dataset\n",
    "class ATLDataLoader(Dataset):\n",
    "    def __init__(self, img_dir, imgSize, lpr_max_len, PreprocFun=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_paths = []\n",
    "        for i in range(len(img_dir)):\n",
    "            self.img_paths += [el for el in paths.list_images(img_dir[i])]\n",
    "        random.shuffle(self.img_paths)\n",
    "        self.img_size = imgSize\n",
    "        self.lpr_max_len = lpr_max_len\n",
    "        if PreprocFun is not None:\n",
    "            self.PreprocFun = PreprocFun\n",
    "        else:\n",
    "            self.PreprocFun = self.transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.img_paths[index]\n",
    "        Image = cv2.imread(filename)\n",
    "        Image = Image[16:64,80:200,:]\n",
    "        height, width, _ = Image.shape\n",
    "        if height != self.img_size[1] or width != self.img_size[0]:\n",
    "            Image = cv2.resize(Image, self.img_size)\n",
    "        Image = self.PreprocFun(Image)\n",
    "\n",
    "        basename = os.path.basename(filename)\n",
    "        imgname, suffix = os.path.splitext(basename)\n",
    "        imgname = imgname.split(\"-\")[0].split(\"_\")[0]\n",
    "        label = list()\n",
    "        for c in imgname:\n",
    "            # one_hot_base = np.zeros(len(CHARS))\n",
    "            # one_hot_base[CHARS_DICT[c]] = 1\n",
    "            label.append(CHARS_DICT[c])\n",
    "\n",
    "        if len(label) == 8:\n",
    "            if self.check(label) == False:\n",
    "                print(imgname)\n",
    "                assert 0, \"Error label ^~^!!!\"\n",
    "\n",
    "        return Image, label, len(label)\n",
    "\n",
    "    def transform(self, img):\n",
    "        img = img.astype('float32')\n",
    "        img -= 127.5\n",
    "        img *= 0.0078125\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "        return img\n",
    "\n",
    "    def check(self, label):\n",
    "        if label[2] != CHARS_DICT['D'] and label[2] != CHARS_DICT['F'] \\\n",
    "                and label[-1] != CHARS_DICT['D'] and label[-1] != CHARS_DICT['F']:\n",
    "            print(\"Error label, Please check!\")\n",
    "            return False\n",
    "        else:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read LPR Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    for _, sample in enumerate(batch):\n",
    "        img, label, length = sample\n",
    "        imgs.append(torch.from_numpy(img))\n",
    "        labels.extend(label)\n",
    "        lengths.append(length)\n",
    "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
    "\n",
    "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, label, target):\n",
    "    #     img = np.transpose(img, (1, 2, 0))\n",
    "    #     img *= 128.\n",
    "    #     img += 127.5\n",
    "    #     img = img.astype(np.uint8)\n",
    "\n",
    "    lb = \"\"\n",
    "    for i in label:\n",
    "        lb += CHARS[i]\n",
    "    tg = \"\"\n",
    "    for j in target.tolist():\n",
    "        tg += CHARS[int(j)]\n",
    "\n",
    "    flag = \"F\"\n",
    "    if lb == tg:\n",
    "        flag = \"T\"\n",
    "    # img = cv2.putText(img, lb, (0,16), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.6, (0, 0, 255), 1)\n",
    "    #     img = cv2ImgAddText(img, lb, (0, 0))\n",
    "    #     cv2.imshow(\"test\", img)\n",
    "    print(\"target: \", tg, \" ### {} ### \".format(flag), \"predict: \", lb)\n",
    "    #     cv2.waitKey()\n",
    "    #     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_parser():\n",
    "#     parser = argparse.ArgumentParser(description='parameters to train net')\n",
    "#     parser.add_argument('--img_size', default=[94, 24], help='the image size')\n",
    "#     parser.add_argument('--test_img_dirs', default=\"./data/test\", help='the test images path')\n",
    "#     parser.add_argument('--dropout_rate', default=0, help='dropout rate.')\n",
    "#     parser.add_argument('--lpr_max_len', default=8, help='license plate number max length.')\n",
    "#     parser.add_argument('--test_batch_size', default=100, help='testing batch size.')\n",
    "#     parser.add_argument('--phase_train', default=False, type=bool, help='train or test phase flag.')\n",
    "#     parser.add_argument('--num_workers', default=8, type=int, help='Number of workers used in dataloading')\n",
    "#     parser.add_argument('--cuda', default=False, type=bool, help='Use cuda to train model')\n",
    "#     parser.add_argument('--show', default=False, type=bool, help='show test image and its predict result or not.')\n",
    "#     parser.add_argument('--pretrained_model', default='./weights/Final_LPRNet_model.pth', help='pretrained base model')\n",
    "\n",
    "#     args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful to build network!\n",
      "load pretrained model successful!\n"
     ]
    }
   ],
   "source": [
    "img_size = (94, 24) ## [94, 24] # [280, 80]  # the image size (80, 280)\n",
    "##test_img_dirs = \"./data_redatcted/ir_patch\"    # the test images path\n",
    "test_img_dirs = \"~/GITHUB/LPRNet_Pytorch/data/test\" # downloaded from GitHub \n",
    "dropout_rate = 0 \n",
    "lpr_max_len = 8    # , help='license plate number max length.')\n",
    "test_batch_size = 100 ## 100  # , help='testing batch size.')\n",
    "phase_train = False  #, type=bool, help='train or test phase flag.')\n",
    "num_workers = 0 ### 8    #, type=int, help='Number of workers used in dataloading')\n",
    "### cuda = False     # , type=bool, help='Use cuda to train model')\n",
    "### show =      #, type=bool, help='show test image and its predict result or not.')\n",
    "pretrained_model = './LPRNet/weights/Final_LPRNet_model.pth'   ## , help='pretrained base model')\n",
    "\n",
    "\n",
    "\n",
    "lprnet = build_lprnet(lpr_max_len = lpr_max_len, phase = False,\n",
    "                      class_num = len(CHARS), dropout_rate = dropout_rate)\n",
    "device = \"cpu\"  ###torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "lprnet.to(device)\n",
    "print(\"Successful to build network!\")\n",
    "\n",
    "# # load pretrained model\n",
    "# if args.pretrained_model:\n",
    "lprnet.load_state_dict(torch.load(pretrained_model, map_location=torch.device('cpu')))\n",
    "print(\"load pretrained model successful!\")\n",
    "\n",
    "# else:\n",
    "#     print(\"[Error] Can't found pretrained mode, please check!\")\n",
    "#     return False\n",
    "\n",
    "#test_img_dirs = os.path.expanduser(args.test_img_dirs)\n",
    "datasets = ATLDataLoader(test_img_dirs.split(','), img_size, lpr_max_len)\n",
    "datasets = LPRDataLoader(test_img_dirs.split(','), img_size, lpr_max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d308d93ebf7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepoch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtest_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m batch_iterator = iter(DataLoader(datasets, test_batch_size,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                  shuffle=True, num_workers=num_workers, collate_fn=collate_fn))\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0m\u001b[1;32m     96\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch_size = len(datasets) // test_batch_size\n",
    "batch_iterator = iter(DataLoader(datasets, test_batch_size,\n",
    "                                 shuffle=True, num_workers=num_workers, collate_fn=collate_fn))\n",
    "\n",
    "Tp = 0\n",
    "Tn_1 = 0\n",
    "Tn_2 = 0\n",
    "t1 = time.time()\n",
    "for i in range(epoch_size):\n",
    "    # load train data\n",
    "    images, labels, lengths = next(batch_iterator)\n",
    "    if i <5:\n",
    "        print(f\"{i}\\t{len(images)}\\t{len(labels)}\\t{len(lengths)}\")\n",
    "    start = 0\n",
    "    targets = []\n",
    "    for length in lengths:\n",
    "        label = labels[start:start+length]\n",
    "        targets.append(label)\n",
    "        start += length\n",
    "    targets = np.array([el.numpy() for el in targets])\n",
    "    imgs = images.numpy().copy()\n",
    "\n",
    "    images = Variable(images)\n",
    "\n",
    "    # forward\n",
    "    prebs = lprnet(images)\n",
    "    # greedy decode\n",
    "    prebs = prebs.cpu().detach().numpy()\n",
    "    preb_labels = list()\n",
    "    for i in range(prebs.shape[0]):\n",
    "        preb = prebs[i, :, :]\n",
    "        preb_label = list()\n",
    "        for j in range(preb.shape[1]):\n",
    "            preb_label.append(np.argmax(preb[:, j], axis=0))\n",
    "        no_repeat_blank_label = list()\n",
    "        pre_c = preb_label[0]\n",
    "        if pre_c != len(CHARS) - 1:\n",
    "            no_repeat_blank_label.append(pre_c)\n",
    "        for c in preb_label: # dropout repeate label and blank label\n",
    "            if (pre_c == c) or (c == len(CHARS) - 1):\n",
    "                if c == len(CHARS) - 1:\n",
    "                    pre_c = c\n",
    "                continue\n",
    "            no_repeat_blank_label.append(c)\n",
    "            pre_c = c\n",
    "        preb_labels.append(no_repeat_blank_label)\n",
    "    for i, label in enumerate(preb_labels):\n",
    "        # show image and its predict label\n",
    "        #         if args.show:\n",
    "        show(imgs[i], label, targets[i])\n",
    "        if len(label) != len(targets[i]):\n",
    "            Tn_1 += 1\n",
    "            continue\n",
    "        if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
    "            Tp += 1\n",
    "        else:\n",
    "            Tn_2 += 1\n",
    "Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
    "print(\"[Info] Test Accuracy: {} [{}:{}:{}:{}]\".format(Acc, Tp, Tn_1, Tn_2, (Tp+Tn_1+Tn_2)))\n",
    "t2 = time.time()\n",
    "print(\"[Info] Test Speed: {}s 1/{}]\".format((t2 - t1) / len(datasets), len(datasets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
