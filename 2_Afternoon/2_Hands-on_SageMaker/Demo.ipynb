{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Install\n",
    "Which SageMaker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version is good\n",
      "Region = us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import sys\n",
    "\n",
    "if int(sagemaker.__version__.split('.')[0]) == 2:\n",
    "    !{sys.executable} -m pip install sagemaker==1.72.0\n",
    "    print(\"Installing previous SageMaker Version. Please restart the kernel\")\n",
    "else:\n",
    "    print(\"Version is good\")\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.session.Session().region_name\n",
    "print(\"Region = {}\".format(region))\n",
    "sm = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.72.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import sleep, gmtime, strftime\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Install experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker-experiments\n",
      "  Using cached sagemaker_experiments-0.1.26-py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.16.63)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.3.4)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.63 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.19.63)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.63->boto3>=1.16.27->sagemaker-experiments) (1.25.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.63->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.63->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n",
      "Installing collected packages: sagemaker-experiments\n",
      "Successfully installed sagemaker-experiments-0.1.26\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-experiments \n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 bucket and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-196811765653'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawbucket= sess.default_bucket() # Alternatively you can use our custom bucket here. \n",
    "\n",
    "prefix = 'sagemaker-modelmonitor' # use this prefix to store all files pertaining to this workshop.\n",
    "\n",
    "dataprefix = prefix + '/data'\n",
    "traindataprefix = prefix + '/train_data'\n",
    "testdataprefix = prefix + '/test_data'\n",
    "testdatanolabelprefix = prefix + '/test_data_no_label'\n",
    "trainheaderprefix = prefix + '/train_headers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-13 16:32:55--  https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5539328 (5.3M) [application/x-httpd-php]\n",
      "Saving to: ‘default of credit card clients.xls.1’\n",
      "\n",
      "default of credit c 100%[===================>]   5.28M  8.72MB/s    in 0.6s    \n",
      "\n",
      "2021-02-13 16:32:56 (8.72 MB/s) - ‘default of credit card clients.xls.1’ saved [5539328/5539328]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\n",
    "data = pd.read_excel('default of credit card clients.xls', header=1)\n",
    "data = data.drop(columns = ['ID'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0      1      20000    2          2         1   24      2      2     -1   \n",
       "1      1     120000    2          2         2   26     -1      2      0   \n",
       "2      0      90000    2          2         2   34      0      0      0   \n",
       "3      0      50000    2          2         1   37      0      0      0   \n",
       "4      0      50000    1          2         1   57     -1      0     -1   \n",
       "\n",
       "   PAY_4  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0     -1  ...        689          0          0          0         0       689   \n",
       "1      0  ...       2682       3272       3455       3261         0      1000   \n",
       "2      0  ...      13559      14331      14948      15549      1518      1500   \n",
       "3      0  ...      49291      28314      28959      29547      2000      2019   \n",
       "4      0  ...      35835      20940      19146      19131      2000     36681   \n",
       "\n",
       "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0         0         0         0         0  \n",
       "1      1000      1000         0      2000  \n",
       "2      1000      1000      1000      5000  \n",
       "3      1200      1100      1069      1000  \n",
       "4     10000      9000       689       679  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={\"default payment next month\": \"Label\"}, inplace=True)\n",
    "lbl = data.Label\n",
    "data = pd.concat([lbl, data.drop(columns=['Label'])], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/data\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('rawdata/rawdata.csv'):\n",
    "    !mkdir rawdata\n",
    "    data.to_csv('rawdata/rawdata.csv', index=None)\n",
    "else:\n",
    "    pass\n",
    "# Upload the raw dataset\n",
    "raw_data_location = sess.upload_data('rawdata', bucket=rawbucket, key_prefix=dataprefix)\n",
    "print(raw_data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Process the data using Amazon SageMaker Processing\n",
    "Import scikit-learn container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.c4.xlarge',\n",
    "                                     instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-test-split-ratio', type=float, default=0.3)\n",
    "    parser.add_argument('--random-split', type=int, default=0)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print('Received arguments {}'.format(args))\n",
    "\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', 'rawdata.csv')\n",
    "    \n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    df = pd.read_csv(input_data_path)\n",
    "    df.sample(frac=1)\n",
    "    \n",
    "    COLS = df.columns\n",
    "    newcolorder = ['PAY_AMT1','BILL_AMT1'] + list(COLS[1:])[:11] + list(COLS[1:])[12:17] + list(COLS[1:])[18:]\n",
    "    \n",
    "    split_ratio = args.train_test_split_ratio\n",
    "    random_state=args.random_split\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop('Label', axis=1), df['Label'], \n",
    "                                                        test_size=split_ratio, random_state=random_state)\n",
    "    \n",
    "    preprocess = make_column_transformer(\n",
    "        (['PAY_AMT1'], StandardScaler()),\n",
    "        (['BILL_AMT1'], MinMaxScaler()),\n",
    "    remainder='passthrough')\n",
    "    \n",
    "    print('Running preprocessing and feature engineering transformations')\n",
    "    train_features = pd.DataFrame(preprocess.fit_transform(X_train), columns = newcolorder)\n",
    "    test_features = pd.DataFrame(preprocess.transform(X_test), columns = newcolorder)\n",
    "    \n",
    "    # concat to ensure Label column is the first column in dataframe\n",
    "    train_full = pd.concat([pd.DataFrame(y_train.values, columns=['Label']), train_features], axis=1)\n",
    "    test_full = pd.concat([pd.DataFrame(y_test.values, columns=['Label']), test_features], axis=1)\n",
    "    \n",
    "    print('Train data shape after preprocessing: {}'.format(train_features.shape))\n",
    "    print('Test data shape after preprocessing: {}'.format(test_features.shape))\n",
    "    \n",
    "    train_features_headers_output_path = os.path.join('/opt/ml/processing/train_headers', 'train_data_with_headers.csv')\n",
    "    \n",
    "    train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_data.csv')\n",
    "    \n",
    "    test_features_output_path = os.path.join('/opt/ml/processing/test', 'test_data.csv')\n",
    "    \n",
    "    print('Saving training features to {}'.format(train_features_output_path))\n",
    "    train_full.to_csv(train_features_output_path, header=False, index=False)\n",
    "    print(\"Complete\")\n",
    "    \n",
    "    print(\"Save training data with headers to {}\".format(train_features_headers_output_path))\n",
    "    train_full.to_csv(train_features_headers_output_path, index=False)\n",
    "                 \n",
    "    print('Saving test features to {}'.format(test_features_output_path))\n",
    "    test_full.to_csv(test_features_output_path, header=False, index=False)\n",
    "    print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "# Copy the preprocessing code over to the s3 bucket\n",
    "codeprefix = prefix + '/code'\n",
    "codeupload = sess.upload_data('preprocessing.py', bucket=rawbucket, key_prefix=codeprefix)\n",
    "print(codeupload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data location = sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/train_data\n",
      "Test data location = sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/test_data\n"
     ]
    }
   ],
   "source": [
    "train_data_location = rawbucket + '/' + traindataprefix\n",
    "test_data_location = rawbucket+'/'+testdataprefix\n",
    "print(\"Training data location = {}\".format(train_data_location))\n",
    "print(\"Test data location = {}\".format(test_data_location))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name sagemaker-scikit-learn-2021-02-13-16-52-23-768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2021-02-13-16-52-23-768\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/data', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/test_data', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'train_data_headers', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/train_headers', 'LocalPath': '/opt/ml/processing/train_headers', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".............................\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(random_split=0, train_test_split_ratio=0.2)\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/rawdata.csv\u001b[0m\n",
      "\u001b[34mRunning preprocessing and feature engineering transformations\u001b[0m\n",
      "\u001b[34mTrain data shape after preprocessing: (24000, 23)\u001b[0m\n",
      "\u001b[34mTest data shape after preprocessing: (6000, 23)\u001b[0m\n",
      "\u001b[34mSaving training features to /opt/ml/processing/train/train_data.csv\u001b[0m\n",
      "\u001b[34mComplete\u001b[0m\n",
      "\u001b[34mSave training data with headers to /opt/ml/processing/train_headers/train_data_with_headers.csv\u001b[0m\n",
      "\u001b[34mSaving test features to /opt/ml/processing/test/test_data.csv\u001b[0m\n",
      "\u001b[34mComplete\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code=codeupload,\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=raw_data_location,\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train',\n",
    "                               destination='s3://' + train_data_location),\n",
    "                               ProcessingOutput(output_name='test_data',\n",
    "                                                source='/opt/ml/processing/test',\n",
    "                                               destination=\"s3://\"+test_data_location),\n",
    "                               ProcessingOutput(output_name='train_data_headers',\n",
    "                                                source='/opt/ml/processing/train_headers',\n",
    "                                               destination=\"s3://\" + rawbucket + '/' + prefix + '/train_headers')],\n",
    "                      arguments=['--train-test-split-ratio', '0.2']\n",
    "                     )\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'train_data':\n",
    "        preprocessed_training_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'test_data':\n",
    "        preprocessed_test_data = output['S3Output']['S3Uri']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Create an Amazon SageMaker Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f5d854a2a10>,experiment_name='gsu-1613235577',description='Predict credit card default from payments data',tags=None,experiment_arn='arn:aws:sagemaker:us-east-1:xxxxxx:experiment/gsu-1613235577',response_metadata={'RequestId': '73d19e86-8869-4f79-8ecf-186b06e918c6', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '73d19e86-8869-4f79-8ecf-186b06e918c6', 'content-type': 'application/x-amz-json-1.1', 'content-length': '86', 'date': 'Sat, 13 Feb 2021 16:59:37 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "# Create a SageMaker Experiment\n",
    "cc_experiment = Experiment.create(\n",
    "    experiment_name=f\"gsu-{int(time.time())}\", \n",
    "    description=\"Predict credit card default from payments data\", \n",
    "    sagemaker_boto_client=sm)\n",
    "print(cc_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tracking parameters used in the Pre-processing pipeline.\n",
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    "    tracker.log_parameters({\n",
    "        \"train_test_split_ratio\": 0.2,\n",
    "        \"random_state\":0\n",
    "    })\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"ccdefault-raw-dataset\", media_type=\"s3/uri\", value=raw_data_location)\n",
    "    tracker.log_input(name=\"ccdefault-train-dataset\", media_type=\"s3/uri\", value=train_data_location)\n",
    "    tracker.log_input(name=\"ccdefault-test-dataset\", media_type=\"s3/uri\", value=test_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.amazon.amazon_estimator:'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker.estimator:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating training-job with name: cc-training-job-1613235963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-13 17:06:03 Starting - Starting the training job...\n",
      "2021-02-13 17:06:06 Starting - Launching requested ML instances......\n",
      "2021-02-13 17:07:18 Starting - Preparing the instances for training......\n",
      "2021-02-13 17:08:20 Downloading - Downloading input data...\n",
      "2021-02-13 17:08:40 Training - Downloading the training image...\n",
      "2021-02-13 17:09:35 Uploading - Uploading generated training model\n",
      "2021-02-13 17:09:35 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[17:09:24] 24000x23 matrix with 552000 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 24000 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.17854\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.17746\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.17704\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.17717\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.17621\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.17608\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.17504\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.17467\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.17513\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.17475\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.17408\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.17354\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.17363\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.17313\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.17325\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.17296\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.17292\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.17317\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.17250\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.17200\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.17175\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.17142\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.17154\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.17171\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.17112\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.17033\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.17046\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.17029\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.17029\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.17029\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.17021\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.16996\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.16971\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.16929\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.16917\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.16908\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.16904\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.16900\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.16867\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.16846\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.16825\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.16817\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.16817\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.16800\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.16804\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.16804\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.16792\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.16737\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.16717\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.16654\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.16667\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.16642\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.16629\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.16542\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.16517\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.16529\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.16537\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.16537\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.16537\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.16529\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.16521\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.16500\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.16500\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.16487\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.16408\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.16400\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.16387\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.16387\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.16387\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.16375\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.16367\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.16333\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.16337\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.16317\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.16296\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.16287\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.16308\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.16300\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.16300\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.16271\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.16246\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.16237\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.16221\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.16171\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.16179\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.16096\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.16079\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.16067\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.16071\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.16042\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.16017\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.16000\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.16029\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.16012\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.16025\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.15975\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.15983\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.15967\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.15937\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.15887\u001b[0m\n",
      "Training seconds: 75\n",
      "Billable seconds: 75\n",
      "Going to sleep....\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', '1.0-1')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://' + train_data_location, content_type='csv')\n",
    "preprocessing_trial_component = tracker.trial_component\n",
    "\n",
    "trial_name = f\"cc-default-training-job-{int(time.time())}\"\n",
    "cc_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "            experiment_name=cc_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm\n",
    "    )\n",
    "\n",
    "cc_trial.add_trial_component(preprocessing_trial_component)\n",
    "cc_training_job_name = \"cc-training-job-{}\".format(int(time.time()))\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    train_max_run=86400,\n",
    "                                    output_path='s3://{}/{}/models'.format(rawbucket, prefix),\n",
    "                                    sagemaker_session=sess) # set to true for distributed training\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        verbosity=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit(inputs = {'train':s3_input_train},\n",
    "       job_name=cc_training_job_name,\n",
    "        experiment_config={\n",
    "            \"TrialName\": cc_trial.trial_name, #log training job in Trials for lineage\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "        wait=True,\n",
    "    )\n",
    "print(\"Going to sleep....\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Deploy the model for offline inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-196811765653/sagemaker-modelmonitor/test_data/test_data.csv to ./test_data.csv\n"
     ]
    }
   ],
   "source": [
    "test_data_path = 's3://' + test_data_location + '/test_data.csv'\n",
    "! aws s3 cp $test_data_path ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.341476</td>\n",
       "      <td>0.201175</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17399.0</td>\n",
       "      <td>19057.0</td>\n",
       "      <td>18453.0</td>\n",
       "      <td>19755.0</td>\n",
       "      <td>19288.0</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.136859</td>\n",
       "      <td>0.199594</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19347.0</td>\n",
       "      <td>18600.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.284364</td>\n",
       "      <td>0.185736</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2864.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2873.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.040569</td>\n",
       "      <td>0.289360</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99998.0</td>\n",
       "      <td>16138.0</td>\n",
       "      <td>17758.0</td>\n",
       "      <td>18774.0</td>\n",
       "      <td>20272.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.079132</td>\n",
       "      <td>0.186502</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6917.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>6469.0</td>\n",
       "      <td>5138.0</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>6488.0</td>\n",
       "      <td>5153.0</td>\n",
       "      <td>7833.0</td>\n",
       "      <td>7130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3    4    5    6     7    8    9  ...  \\\n",
       "0  0 -0.341476  0.201175   20000.0  1.0  1.0  2.0  33.0  1.0  2.0  ...   \n",
       "1  0 -0.136859  0.199594   20000.0  2.0  2.0  2.0  35.0  0.0  0.0  ...   \n",
       "2  0 -0.284364  0.185736  230000.0  2.0  1.0  1.0  44.0  1.0 -1.0  ...   \n",
       "3  0 -0.040569  0.289360  100000.0  1.0  2.0  1.0  42.0  0.0  0.0  ...   \n",
       "4  0  0.079132  0.186502  150000.0  1.0  1.0  2.0  29.0 -2.0 -2.0  ...   \n",
       "\n",
       "        14       15       16       17       18      19      20      21  \\\n",
       "0  17399.0  19057.0  18453.0  19755.0  19288.0  2260.0     0.0  1600.0   \n",
       "1  19347.0  18600.0  19000.0  19000.0  20000.0     0.0  1000.0     0.0   \n",
       "2    949.0   2864.0    933.0      0.0      0.0  2873.0   933.0     0.0   \n",
       "3  99998.0  16138.0  17758.0  18774.0  20272.0  2000.0  2000.0  2000.0   \n",
       "4   6917.0    831.0   6469.0   5138.0   7810.0   833.0  6488.0  5153.0   \n",
       "\n",
       "       22      23  \n",
       "0     0.0   644.0  \n",
       "1  1000.0     0.0  \n",
       "2     0.0     0.0  \n",
       "3  2000.0  2000.0  \n",
       "4  7833.0  7130.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full = pd.read_csv('test_data.csv', names = [str(x) for x in range(len(data.columns))])\n",
    "test_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = test_full['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating model with name: cc-training-job-1613235963\n",
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2021-02-13-17-20-36-108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm waiting....\n",
      "..............................\n",
      "\u001b[34m[2021-02-13:17:25:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-02-13:17:25:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-02-13:17:25:24:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35m[2021-02-13:17:25:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-02-13:17:25:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-02-13:17:25:24:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021/02/13 17:25:24 [crit] 20#20: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Feb/2021:17:25:24 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021/02/13 17:25:24 [crit] 20#20: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Feb/2021:17:25:24 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-02-13 17:25:24 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-02-13 17:25:24 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2021-02-13 17:25:24 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-02-13 17:25:24 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2021-02-13 17:25:24 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-02-13 17:25:24 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2021-02-13 17:25:24 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[35m[2021-02-13 17:25:24 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2021-02-13 17:25:24 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[35m[2021-02-13 17:25:24 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-02-13 17:25:24 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2021-02-13 17:25:24 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2021-02-13 17:25:24 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[35m[2021-02-13 17:25:24 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[34m[2021-02-13:17:25:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Feb/2021:17:25:26 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Feb/2021:17:25:26 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-02-13:17:25:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Feb/2021:17:25:26 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Feb/2021:17:25:26 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-02-13:17:25:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-02-13:17:25:26:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Feb/2021:17:25:26 +0000] \"POST /invocations HTTP/1.1\" 200 118174 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-02-13:17:25:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-02-13:17:25:26:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Feb/2021:17:25:26 +0000] \"POST /invocations HTTP/1.1\" 200 118174 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-02-13T17:25:26.291:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "CPU times: user 552 ms, sys: 49.1 ms, total: 601 ms\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sm_transformer = xgb.transformer(1, 'ml.m5.xlarge', accept = 'text/csv')\n",
    "\n",
    "# start a transform job\n",
    "sm_transformer.transform(test_data_path, split_type='Line', input_filter='$[1:]', content_type='text/csv')\n",
    "print(\"I'm waiting....\")\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>4460</td>\n",
       "      <td>815</td>\n",
       "      <td>5275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>243</td>\n",
       "      <td>482</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4703</td>\n",
       "      <td>1297</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "Actual                     \n",
       "0.0        4460   815  5275\n",
       "1.0         243   482   725\n",
       "All        4703  1297  6000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')\n",
    "\n",
    "output = get_csv_output_from_s3(sm_transformer.output_path, 'test_data.csv.out')\n",
    "output_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "output_df.head(8)\n",
    "output_df['Predicted']=np.round(output_df.values)\n",
    "output_df['Label'] = label\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix = pd.crosstab(output_df['Predicted'], output_df['Label'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy = 0.7787999999999999\n",
      "Accuracy Score = 0.8236666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Accuracy = {}\".format(1- np.unique(data['Label'], return_counts=True)[1][1]/(len(data['Label']))))\n",
    "print(\"Accuracy Score = {}\".format(accuracy_score(label, output_df['Predicted'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Deploy the model as an endpoint and set up data capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created: arn:aws:sagemaker:us-east-1:xxxxxx:model/cc-training-job-1613235963\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker import RealTimePredictor\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "latest_training_job = sm_client.list_training_jobs(MaxResults=1,\n",
    "                                                SortBy='CreationTime',\n",
    "                                                SortOrder='Descending')\n",
    "\n",
    "training_job_name=TrainingJobName=latest_training_job['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "\n",
    "training_job_description = sm_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "model_data = training_job_description['ModelArtifacts']['S3ModelArtifacts']\n",
    "container_uri = training_job_description['AlgorithmSpecification']['TrainingImage']\n",
    "\n",
    "# create a model.\n",
    "def create_model(role, model_name, container_uri, model_data):\n",
    "    return sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        PrimaryContainer={\n",
    "        'Image': container_uri,\n",
    "        'ModelDataUrl': model_data,\n",
    "        },\n",
    "        ExecutionRoleArn=role)\n",
    "    \n",
    "\n",
    "try:\n",
    "    model = create_model(role, training_job_name, container_uri, model_data)\n",
    "except Exception as e:\n",
    "        sm_client.delete_model(ModelName=training_job_name)\n",
    "        model = create_model(role, training_job_name, container_uri, model_data)\n",
    "        \n",
    "\n",
    "print('Model created: '+model['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_capture_upload_path = 's3://{}/{}/monitoring/datacapture'.format(rawbucket, prefix)\n",
    "\n",
    "data_capture_configuration = {\n",
    "    \"EnableCapture\": True,\n",
    "    \"InitialSamplingPercentage\": 100,\n",
    "    \"DestinationS3Uri\": s3_capture_upload_path,\n",
    "    \"CaptureOptions\": [\n",
    "        { \"CaptureMode\": \"Output\" },\n",
    "        { \"CaptureMode\": \"Input\" }\n",
    "    ],\n",
    "    \"CaptureContentTypeHeader\": {\n",
    "       \"CsvContentTypes\": [\"text/csv\"],\n",
    "       \"JsonContentTypes\": [\"application/json\"]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint configuration created: arn:aws:sagemaker:us-east-1:xxxxxx:endpoint-config/cc-training-job-1613235963\n"
     ]
    }
   ],
   "source": [
    "def create_endpoint_config(model_config, data_capture_config): \n",
    "    return sm_client.create_endpoint_config(\n",
    "                        EndpointConfigName=model_config,\n",
    "                        ProductionVariants=[\n",
    "                                {\n",
    "                                    'VariantName': 'AllTraffic',\n",
    "                                    'ModelName': model_config,\n",
    "                                    'InitialInstanceCount': 1,\n",
    "                                    'InstanceType': 'ml.m4.xlarge',\n",
    "                                    'InitialVariantWeight': 1.0,\n",
    "                        },\n",
    "\n",
    "                            ],\n",
    "                        DataCaptureConfig=data_capture_config\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    endpoint_config = create_endpoint_config(training_job_name, data_capture_configuration)\n",
    "except Exception as e:\n",
    "    sm_client.delete_endpoint_config(EndpointConfigName=endpoint)\n",
    "    endpoint_config = create_endpoint_config(training_job_name, data_capture_configuration)\n",
    "\n",
    "print('Endpoint configuration created: '+ endpoint_config['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint created: arn:aws:sagemaker:us-east-1:xxxxxx:endpoint/cc-training-job-1613235963\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = training_job_name\n",
    "def create_endpoint(endpoint_name, config_name):\n",
    "    return sm_client.create_endpoint(\n",
    "                                    EndpointName=endpoint_name,\n",
    "                                    EndpointConfigName=training_job_name\n",
    "                                )\n",
    "\n",
    "\n",
    "try:\n",
    "    endpoint = create_endpoint(endpoint_name, endpoint_config)\n",
    "except Exception as e:\n",
    "    sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint = create_endpoint(endpoint_name, endpoint_config)\n",
    "\n",
    "print('Endpoint created: '+ endpoint['EndpointArn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 test_data.csv > test_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: 0,-0.34147611300851444,0.20117515020922977,20000.0,1.0,1.0,2.0,33.0,1.0,2.0,2.0,2.0,2.0,2.0,17399.0,19057.0,18453.0,19755.0,19288.0,2260.0,0.0,1600.0,0.0,644.0\n",
      "Response: b'0.5837969183921814'\n",
      "\n",
      "Payload: 0,-0.1368591509062042,0.199593596626019,20000.0,2.0,2.0,2.0,35.0,0.0,0.0,2.0,0.0,0.0,0.0,19347.0,18600.0,19000.0,19000.0,20000.0,0.0,1000.0,0.0,1000.0,0.0\n",
      "Response: b'0.32431045174598694'\n",
      "\n",
      "Payload: 0,-0.28436390799819317,0.18573554845823184,230000.0,2.0,1.0,1.0,44.0,1.0,-1.0,-1.0,-1.0,-1.0,-2.0,949.0,2864.0,933.0,0.0,0.0,2873.0,933.0,0.0,0.0,0.0\n",
      "Response: b'0.24034710228443146'\n",
      "\n",
      "Payload: 0,-0.04056881579923467,0.2893596406815476,100000.0,1.0,2.0,1.0,42.0,0.0,0.0,0.0,0.0,0.0,0.0,99998.0,16138.0,17758.0,18774.0,20272.0,2000.0,2000.0,2000.0,2000.0,2000.0\n",
      "Response: b'0.06280174106359482'\n",
      "\n",
      "Payload: 0,0.07913210703061682,0.18650166485093062,150000.0,1.0,1.0,2.0,29.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,6917.0,831.0,6469.0,5138.0,7810.0,833.0,6488.0,5153.0,7833.0,7130.0\n",
      "Response: b'0.08418034762144089'\n",
      "\n",
      "Payload: 1,-0.34147611300851444,0.1932005252116958,50000.0,1.0,2.0,2.0,25.0,-1.0,3.0,2.0,0.0,0.0,0.0,10386.0,9993.0,9993.0,15300.0,0.0,0.0,200.0,5307.0,0.0,0.0\n",
      "Response: b'0.5108723044395447'\n",
      "\n",
      "Payload: 1,-0.01854240164351539,0.29278031201432714,140000.0,2.0,2.0,2.0,26.0,0.0,0.0,0.0,0.0,0.0,0.0,105246.0,104781.0,105334.0,107699.0,106828.0,5087.0,3605.0,3894.0,3785.0,3304.0\n",
      "Response: b'0.08880854398012161'\n",
      "\n",
      "Payload: 0,-0.1311419122592279,0.1814786155980859,280000.0,1.0,1.0,2.0,31.0,1.0,-1.0,-1.0,0.0,0.0,-2.0,3495.0,2783.0,2001.0,-339.0,-1180.0,2783.0,0.0,0.0,0.0,0.0\n",
      "Response: b'0.1815711110830307'\n",
      "\n",
      "Payload: 0,-0.0958755770263003,0.19346356946669968,500000.0,2.0,1.0,2.0,36.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,4079.0,3943.0,3338.0,1224.0,31022.0,4283.0,3338.0,1224.0,31022.0,1088.0\n",
      "Response: b'0.07961677014827728'\n",
      "\n",
      "Payload: 0,-0.34147611300851444,0.18202662446267728,310000.0,2.0,2.0,1.0,44.0,-1.0,-1.0,-2.0,-2.0,-2.0,-2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "Response: b'0.2123846560716629'\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import RealTimePredictor\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "predictor = RealTimePredictor(endpoint=endpoint_name, content_type = 'text/csv')\n",
    "\n",
    "with open('test_sample.csv', 'r') as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip('\\n')\n",
    "        print(f\"Payload: {payload}\")\n",
    "        response = predictor.predict(data=payload[2:])\n",
    "        print(f\"Response: {response}\\n\")\n",
    "        sleep(0.5)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_default_monitor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-0aeeb3f15375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_default_monitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_monitoring_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# actually wait for the deletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_default_monitor' is not defined"
     ]
    }
   ],
   "source": [
    "# my_default_monitor.delete_monitoring_schedule()\n",
    "# time.sleep(10) # actually wait for the deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '7e0c12d6-9abf-4af9-aa4f-867d54ceee6a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7e0c12d6-9abf-4af9-aa4f-867d54ceee6a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sat, 13 Feb 2021 18:10:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_endpoint(EndpointName = endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
